<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>爬虫 on NieMinghua-blog</title>
    <link>https://blog.github.io/tags/%E7%88%AC%E8%99%AB/</link>
    <description>Recent content in 爬虫 on NieMinghua-blog</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <lastBuildDate>Sun, 21 Jun 2020 14:57:00 +0800</lastBuildDate>
    
	<atom:link href="https://blog.github.io/tags/%E7%88%AC%E8%99%AB/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>Scrapy框架</title>
      <link>https://blog.github.io/scrapy%E6%A1%86%E6%9E%B6/</link>
      <pubDate>Sun, 21 Jun 2020 14:57:00 +0800</pubDate>
      
      <guid>https://blog.github.io/scrapy%E6%A1%86%E6%9E%B6/</guid>
      <description>SCRAPY爬虫框架入门 爬取中国天气网的一个小demo
  建立框架 scrapy startproject myspider[project_name]  看一下项目的结构目录
  scrapy.cfg: 项目的配置文件
hellospider/: 该项目的python模块。之后您将在此加入代码。
hellospider/items.py:需要提取的数据结构定义文件。
hellospider/middlewares.py: 是和Scrapy的请求/响应处理相关联的框架。
hellospider/pipelines.py: 用来对items里面提取的数据做进一步处理，如保存等。
hellospider/settings.py: 项目的配置文件。
hellospider/spiders/: 放置spider代码的目录。
 在items.py中定义自己要抓取的数据 import scrapy class HellospiderItem(scrapy.Item): # 天气 weather = scrapy.Field() # 最高温度 temperature_up = scrapy.Field() # 最低温度 temperature_low = scrapy.Field() # 风力 wind = scrapy.Field() pass  【注】上面类中的title、author、reply就像是字典中的“键”，爬到的数据就像似字典中的“值”。
  在spiders目录下创建爬虫文件myspider.py import scrapy from ..items import HellospiderItem import sys class MySpider(scrapy.Spider): # 设置名称 name = &#39;myspider&#39; start_urls = [ &#39;http://www.</description>
    </item>
    
    <item>
      <title>文字识别验证码自动登录</title>
      <link>https://blog.github.io/%E6%96%87%E5%AD%97%E8%AF%86%E5%88%AB%E9%AA%8C%E8%AF%81%E7%A0%81%E8%87%AA%E5%8A%A8%E7%99%BB%E5%BD%95/</link>
      <pubDate>Sun, 26 Apr 2020 16:19:48 +0800</pubDate>
      
      <guid>https://blog.github.io/%E6%96%87%E5%AD%97%E8%AF%86%E5%88%AB%E9%AA%8C%E8%AF%81%E7%A0%81%E8%87%AA%E5%8A%A8%E7%99%BB%E5%BD%95/</guid>
      <description>识别图片验证码自动登录demo   使用selenium需要下载chromedriver 网址: http://npm.taobao.org/mirrors/chromedriver/ 下载跟自己浏览器版本号最接近的版本.
  https://cloud.baidu.com/ 百度开发平台. https://cloud.baidu.com/doc/OCR/s/zk3h7xz52 文字识别开发文档
  导包
import random from selenium import webdriver import time import requests import json import base64 import urllib    建立浏览器对象和抓取验证码图片
# 建立浏览器对象 browser = webdriver.Chrome(&#39;D:\python\python6\chromedriver.exe&#39;) # 打开网址 browser.get(&#39;http://localhost:8080/register&#39;) # 等待5秒 time.sleep(3) # 选择元素 myimg = browser.find_element_by_xpath(&#39;//*[@id=&amp;quot;app&amp;quot;]/div/section/div[2]/table/tr[3]/td[2]/img&#39;) # 截取元素图 myimg.screenshot(&#39;register.png&#39;) # 随机生成用户名与密码 num = &#39;0123456789qwertyuiopasdfghjklzxcvbnm&#39; nums = &#39;0123456789&#39;    调用百度接口识别我们截图的验证码图片
def Disc_img(): # 请求调用百度接口 res = requests.</description>
    </item>
    
  </channel>
</rss>